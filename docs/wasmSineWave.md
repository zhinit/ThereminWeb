# WASM Sine Wave: Architecture & Workflow

This document explains how the C++ to WebAssembly audio pipeline works in this project.

## Overview

This project plays a 440Hz sine wave generated by C++ code compiled to WebAssembly (WASM), running inside a browser's AudioWorklet for real-time audio processing.

**The core idea:** Write audio DSP in C++, compile it to WASM, and control it from a React UI.

---

## Files Created

| File                               | Purpose                                          |
| ---------------------------------- | ------------------------------------------------ |
| `dsp/oscillator.cpp`               | C++ sine wave oscillator with Embind bindings    |
| `frontend/public/audio-engine.js`  | Compiled WASM + JavaScript glue code (generated) |
| `frontend/public/dsp-processor.js` | AudioWorklet processor that runs the WASM        |
| `frontend/src/App.tsx`             | React component with play/stop UI                |
| `frontend/vite.config.ts`          | Vite config with CORS headers for WASM           |

---

## How Everything Communicates

```
┌─────────────────────────────────────────────────────────────────┐
│                        MAIN THREAD                               │
│  ┌─────────────┐      ┌─────────────────┐      ┌─────────────┐  │
│  │   App.tsx   │─────▶│  AudioContext   │─────▶│   Speakers  │  │
│  │  (React UI) │      │                 │      │             │  │
│  └──────┬──────┘      └────────┬────────┘      └─────────────┘  │
│         │                      │                                 │
│         │ postMessage          │ .connect()                      │
│         ▼                      │                                 │
│  ┌─────────────────────────────┴───────────────────────────────┐│
│  │                    AudioWorkletNode                          ││
│  │                    (bridge to worklet)                       ││
│  └──────────────────────────┬──────────────────────────────────┘│
└─────────────────────────────┼───────────────────────────────────┘
                              │ MessagePort
┌─────────────────────────────┼───────────────────────────────────┐
│                     AUDIO THREAD                                 │
│  ┌──────────────────────────┴──────────────────────────────────┐│
│  │                 DSPProcessor (AudioWorklet)                  ││
│  │  ┌─────────────────────────────────────────────────────┐    ││
│  │  │              WASM Module (audio-engine.js)          │    ││
│  │  │  ┌───────────────────────────────────────────────┐  │    ││
│  │  │  │           SineOscillator (C++ class)          │  │    ││
│  │  │  │  - process() generates audio samples          │  │    ││
│  │  │  │  - setPlaying(bool) starts/stops              │  │    ││
│  │  │  └───────────────────────────────────────────────┘  │    ││
│  │  └─────────────────────────────────────────────────────┘    ││
│  └─────────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────────┘
```

### Communication Flow

1. **User clicks button** → React calls `togglePlay()`
2. **React sends message** → `workletNode.port.postMessage({ type: "play" })`
3. **Worklet receives message** → `handleMessage()` calls `engine.setPlaying(true)`
4. **WASM generates audio** → `process()` fills buffer with sine wave samples
5. **Browser plays audio** → Samples copied from WASM heap to browser output buffer

---

## The Compilation Command

```bash
emcc dsp/oscillator.cpp \
    -o frontend/public/audio-engine.js \
    -s MODULARIZE=1 \
    -s EXPORT_NAME="createAudioEngine" \
    -s ENVIRONMENT='web,worker,shell' \
    -s SINGLE_FILE=1 \
    -s EXPORTED_FUNCTIONS='["_malloc","_free"]' \
    -s EXPORTED_RUNTIME_METHODS='["ccall","cwrap","HEAPF32"]' \
    --bind
```

### Flag Breakdown

**`-o frontend/public/audio-engine.js`**
Output file location. Creates the JS glue code.

**`-s MODULARIZE=1`**
Wraps output in a factory function instead of executing immediately.
Required for async loading in AudioWorklets.

**`-s EXPORT_NAME="createAudioEngine"`**
The factory function name. JS calls `await createAudioEngine()` to get the module.

**`-s ENVIRONMENT='web,worker,shell'`**
Target environments. `shell` is needed because we load via `new Function()`.

**`-s SINGLE_FILE=1`**
Embeds WASM binary as base64 inside the JS file. No separate `.wasm` file needed.

**`-s EXPORTED_FUNCTIONS='["_malloc","_free"]'`**
Expose C memory functions. Needed to allocate buffer space in WASM heap.

**`-s EXPORTED_RUNTIME_METHODS='["ccall","cwrap","HEAPF32"]'`**
Expose runtime helpers. `HEAPF32` is a Float32Array view of WASM memory.

**`--bind`**
Enables Embind, which lets you expose C++ classes to JavaScript
with `EMSCRIPTEN_BINDINGS`.

---

## General Workflow

### Development Cycle

1. **Edit C++ code** in `dsp/oscillator.cpp`
2. **Recompile** with `emcc` command above
3. **Hard refresh browser** (Cmd+Shift+R) to clear cache
4. **Test** by clicking the button

### Adding New Functionality

To expose a new C++ method to JavaScript:

1. Add the method to your C++ class
2. Add it to the `EMSCRIPTEN_BINDINGS` block: `.function("methodName", &ClassName::methodName)`
3. Recompile
4. Call it from JavaScript: `this.engine.methodName(args)`

---

## Key WASM Concepts

### What is WebAssembly?

WebAssembly (WASM) is a binary instruction format that runs in browsers at near-native speed. It's a compilation target for languages like C, C++, and Rust.

### Why Use WASM for Audio?

- **Performance**: Audio DSP needs to process thousands of samples per second with minimal latency
- **Existing Code**: Reuse battle-tested C++ audio libraries (like JUCE)
- **Deterministic**: No garbage collection pauses during audio processing

### The WASM Memory Model

WASM has its own linear memory (heap), separate from JavaScript. To share audio data:

1. **Allocate** space in WASM heap with `_malloc(bytes)`
2. **Process** audio in C++, which writes to that memory
3. **Read** results via `HEAPF32`, a typed array view of WASM memory
4. **Copy** to browser's audio buffer with `output.set(wasmOutput)`

### Embind

Embind is Emscripten's system for exposing C++ to JavaScript. It's enabled with `--bind` and configured with the `EMSCRIPTEN_BINDINGS` macro:

```cpp
EMSCRIPTEN_BINDINGS(module_name) {
    emscripten::class_<ClassName>("ClassName")
        .constructor()
        .function("jsName", &ClassName::cppMethod);
}
```

This creates a JavaScript-accessible class that wraps your C++ class.

---

## AudioWorklet Basics

### Why AudioWorklet?

The Web Audio API runs audio processing on a dedicated high-priority thread. AudioWorklet is the modern way to run custom audio code on this thread.

### The process() Method

The browser calls `process()` ~375 times per second (at 48kHz sample rate with 128-sample buffers). Each call must:

1. Fill the output buffer with audio samples
2. Return `true` to keep processing, or `false` to stop

### Limitations

- No access to DOM, `fetch`, or `importScripts` reliably
- Limited JavaScript APIs available
- Must be loaded from a separate file via `addModule()`

This is why we load the WASM in the main thread and send it to the worklet via `postMessage`.

---

## Troubleshooting

**No sound**
Check browser console for errors. Ensure AudioContext is resumed after user gesture.

**`_malloc is not a function`**
Add `_malloc` to `EXPORTED_FUNCTIONS` and recompile.

**`HEAPF32 was not exported`**
Add `HEAPF32` to `EXPORTED_RUNTIME_METHODS` and recompile.

**`importScripts is not defined`**
Load WASM in main thread and send via postMessage (already done).

**Changes not appearing**
Hard refresh (Cmd+Shift+R) to clear cached WASM.

---

## Next Steps

- Add frequency control from the UI
- Implement more complex oscillators (saw, square, triangle)
- Add filters and effects in C++
- Eventually integrate JUCE DSP modules
